{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f1412a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b258b4e",
   "metadata": {},
   "source": [
    "## Low pass filters\n",
    "\n",
    "- Low pass filters, such as box and Gaussian kernels, are employed for `image smoothing`, `reducing noise` and `irrelevant details.`\n",
    "- Their convolution operation averages pixel values, providing a trade-off between noise reduction and loss of fine details in the processed image.\n",
    "\n",
    "1) Box Filter    (first-order derivative)\n",
    "2) Gaussian Filter   (second-order derivative )\n",
    "3) Median Filter  (Non-linear filter (not explicitly low-pass or high-pass)).\n",
    "4) Mean Filter    (first-order derivative)\n",
    "5) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b83b9b2",
   "metadata": {},
   "source": [
    "## Low pass filtering with a box kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5597522",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../contents/elephant.jpg', 0)\n",
    "\n",
    "# kernel_size = 3\n",
    "# box_kernel =  np.ones((kernel_size, kernel_size), np.float32) / (kernel_size * kernel_size)\n",
    "box_kernel = np.ones((3,3), np.float32) / (3*3)\n",
    "\n",
    "# Apply the filter using cv2.filter2D\n",
    "filtered_img = cv2.filter2D(img, -1, box_kernel)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Low Pass Filtered', filtered_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09029e49",
   "metadata": {},
   "source": [
    "## Low pass Gaussian Filter Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23372080",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../contents/elephant.jpg', 0)\n",
    "\n",
    "# Apply the filter using cv2.filter2D\n",
    "imgGaussianBlur = cv2.GaussianBlur(img, (3,3), 0)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Low Pass Filtered', imgGaussianBlur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a8fc75",
   "metadata": {},
   "source": [
    "## Low pass filtering and thresholding for region extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4f62965",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../contents/log.tif', 0)\n",
    "\n",
    "kernel_size = 5\n",
    "box_kernel =  np.ones((kernel_size, kernel_size), np.float32) / (kernel_size * kernel_size)\n",
    "\n",
    "# Apply the filter using cv2.filter2D\n",
    "filteredImg = cv2.filter2D(img, -1, box_kernel)\n",
    "\n",
    "# hist, bins = np.histogram(filteredImg.flatten(), bins=256, range=[0, 256])\n",
    "\n",
    "# # Plot the histogram\n",
    "# plt.plot(hist, color='black')\n",
    "# plt.xlabel('Pixel Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Histogram of the Image')\n",
    "# plt.show()\n",
    "threshold_value = 15\n",
    "_, imgThresholded = cv2.threshold(filteredImg, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('filteredImg', filteredImg)\n",
    "cv2.imshow('Thresholded Img', imgThresholded)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605b9d9d",
   "metadata": {},
   "source": [
    "## Median Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61eba4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../contents/circuit.jpg', 0)\n",
    "\n",
    "imgGuass = cv2.GaussianBlur(img, (3,3), 0)\n",
    "imgMedian = cv2.medianBlur(img, 3)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow(\"Gaussian Blurred\", imgGuass)\n",
    "cv2.imshow('Median Blurred', imgMedian)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7ab087",
   "metadata": {},
   "source": [
    "## High Pass Filters\n",
    "- High pass filters are commonly used for sharpening and edge detection in image processing.\n",
    "\n",
    "1) Laplacian Filter (2st order derivative)\n",
    "2) Sobel Filter (1st order derivative)\n",
    "3) Prewit Filter  (1st order derivative)\n",
    "4) Gradient Filter (2st order derivative)\n",
    "5) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a551ae7",
   "metadata": {},
   "source": [
    "## Image sharpening using the Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca30d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../contents/pca_test1.jpg', 0)\n",
    "\n",
    "laplacian = cv2.Laplacian(img, cv2.CV_64F)\n",
    "\n",
    "# Convert the result to uint8 (required for display)\n",
    "laplacian = np.uint8(np.absolute(laplacian))\n",
    "\n",
    "sharpend_img = cv2.subtract(img, laplacian)\n",
    "\n",
    "img = cv2.resize(img, (500,500))\n",
    "sharpend_img = cv2.resize(sharpend_img, (500,500))\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Sharpend Image', sharpend_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14170b5",
   "metadata": {},
   "source": [
    "## UNSHARP MASKING AND HIGHBOOST FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e7c00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../contents/elephant.jpg', 0)\n",
    "\n",
    "blurrImg = cv2.GaussianBlur(img, (5,5), 0)\n",
    "\n",
    "# Subtract the blurred image from the original (the resulting difference is called the mask.)\n",
    "mask = cv2.subtract(img, blurrImg)\n",
    "\n",
    "sharpImg = cv2.add(img, mask)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Blurred', blurrImg)\n",
    "cv2.imshow(\"mask\", mask)\n",
    "cv2.imshow(\"Sharped Img\", sharpImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4caecd",
   "metadata": {},
   "source": [
    "## USING FIRST-ORDER DERIVATIVES FOR IMAGE SHARPENINGâ€”THE GRADIENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3082b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../contents/LinuxLogo.jpg', 0)\n",
    "\n",
    "# Apply the Sobel operator for gradient in x and y directions\n",
    "gradient_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "gradient_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "# Combine the gradients to get the overall gradient magnitude\n",
    "gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "\n",
    "# Convert the result to uint8 (required for display)\n",
    "gradient_magnitude = np.uint8(np.absolute(gradient_magnitude))\n",
    "\n",
    "sharpened_img = cv2.subtract(img, gradient_magnitude)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Gradient Magnitude', gradient_magnitude)\n",
    "cv2.imshow('Sharpened', sharpened_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bde1ad",
   "metadata": {},
   "source": [
    "## Using gradient for edge enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c75ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../contents/LinuxLogo.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Compute gradient magnitude\n",
    "gradient_magnitude = cv2.magnitude(cv2.Sobel(img, cv2.CV_64F, 1, 0), cv2.Sobel(img, cv2.CV_64F, 0, 1))\n",
    "\n",
    "# Enhance edges\n",
    "enhanced_image = np.uint8(255 * (gradient_magnitude / np.max(gradient_magnitude)))\n",
    "\n",
    "# Display the results\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Enhanced Image', enhanced_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026bb49c",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "- Normalization refers to the process of scaling pixel intensity values in an image to a standard range, often between 0 and 255 for 8-bit images. This ensures consistent and optimal use of intensity values, facilitating better visual interpretation and analysis of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "886e82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../contents/gradient.tif', 0)\n",
    "\n",
    "\n",
    "def normalize_intensity(image):\n",
    "    min_intensity = np.min(image)\n",
    "    max_intensity = np.max(image)\n",
    "    if min_intensity == max_intensity:\n",
    "        return image.astype(np.uint8)\n",
    "\n",
    "    normalized_image = ((image - min_intensity) / (max_intensity - min_intensity)) * 255\n",
    "    return normalized_image.astype(np.uint8)\n",
    "\n",
    "normalizeImg = normalize_intensity(img)\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Normalized', normalizeImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
