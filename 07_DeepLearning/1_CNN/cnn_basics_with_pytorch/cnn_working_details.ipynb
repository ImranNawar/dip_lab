{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a CNN-based architecture using PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from torch.optim import SGD, Adam\n",
    "from torchvision import datasets\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor([[[[1,2,3,4],[2,3,4,5],[5,6,7,8],[1,3,4,5]]],[[[-1,2,3,-4],[2,-3,4,5],[-5,6,-7,8],[-1,-3,-4,-5]]]]).to(device).float()\n",
    "X_train /= 8\n",
    "y_train = torch.tensor([0,1]).to(device).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 1, kernel_size=3),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(1, 1),\n",
    "        nn.Sigmoid()\n",
    "    ).to(device)\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv2d: 1-1                            [-1, 1, 2, 2]             10\n",
       "├─MaxPool2d: 1-2                         [-1, 1, 1, 1]             --\n",
       "├─ReLU: 1-3                              [-1, 1, 1, 1]             --\n",
       "├─Flatten: 1-4                           [-1, 1]                   --\n",
       "├─Linear: 1-5                            [-1, 1]                   2\n",
       "├─Sigmoid: 1-6                           [-1, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 12\n",
       "Trainable params: 12\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, loss_fn, optimizer = get_model()\n",
    "summary(model, X_train, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train on Batches of Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(x, y, model, opt, loss_fn):\n",
    "    model.train()\n",
    "    prediction = model(x)\n",
    "    batch_loss = loss_fn(prediction.squeeze(0), y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return batch_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(TensorDataset(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Batch:` A subset of the entire dataset used in one iteration of the training process. Training on batches allows models to update weights more frequently and manage memory more efficiently, especially with large datasets.\n",
    "\n",
    "`TensorDataset:` A PyTorch utility that combines two tensors into a dataset. It allows you to pair input features (X_train) with their corresponding labels (y_train).\n",
    "\n",
    "`trn_dl:` This is the DataLoader instance that provides batches of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(loader, model, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Epoch 2000/2000 - Avg Loss: 0.0164, Train Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2000):\n",
    "    epoch_loss = 0\n",
    "    for ix, batch in enumerate(trn_dl):\n",
    "        x, y = batch\n",
    "        batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
    "        epoch_loss += batch_loss\n",
    "\n",
    "train_accuracy = calculate_accuracy(trn_dl, model, device)\n",
    "avg_loss = epoch_loss / len(trn_dl)\n",
    "print(f'Final Epoch {epoch + 1}/2000 - Avg Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0321]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagating the output\n",
    "This part of the code is demonstrating how the CNN model processes an input image step-by-step. Here's a simple explanation:\n",
    "\n",
    "1. It extracts the weights and biases from the convolutional layer `(cnn_w, cnn_b)` and the linear laye+r -(lin_w, lin_b) of the trained model.\n",
    "\n",
    "2. It then manually applies the convolutional operation on the input image (X_train[0]) using these extracted weights. This is done by sliding the convolutional filter over the image and computing the sum of element-wise multiplication plus the bias.\n",
    "\n",
    "3. The result of this convolution is stored in the `sumprod` tensor.\n",
    "\n",
    "4. Next, it applies the ReLU activation function to `sumprod` using clamp_min_(0), which sets all negative values to zero.\n",
    "\n",
    "5. It then simulates the max pooling operation by taking the maximum value from `sumprod`.\n",
    "\n",
    "6. The pooling output is then passed through the linear layer by multiplying with lin_w and adding lin_b.\n",
    "\n",
    "7. Finally, it applies the sigmoid activation function to this result.\n",
    "\n",
    "This process essentially \"unrolls\" the forward pass of the CNN, showing how the input is transformed at each step. It's a way to visualize and understand the inner workings of the neural network, demonstrating how the image data is processed through each layer to produce the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract various layers of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1)),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " ReLU(),\n",
       " Flatten(start_dim=1, end_dim=-1),\n",
       " Linear(in_features=1, out_features=1, bias=True),\n",
       " Sigmoid()]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.children())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extract the layers among all the layers of the model that have the `weight` attribute associated with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cnn_w, cnn_b), (lin_w, lin_b) = [(layer.weight.data, layer.bias.data) for layer in list(model.children()) if hasattr(layer, 'weight')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_im, w_im = X_train.shape[2:]\n",
    "h_conv, w_conv= cnn_w.shape[2:]\n",
    "sumprod = torch.zeros((h_im -h_conv +1, w_im - w_conv + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(h_im - h_conv + 1):\n",
    "    for j in range(w_im - w_conv + 1):\n",
    "        img_subset =X_train[0, 0, i:(i+3), j:(j+3)]\n",
    "        model_filter = cnn_w.reshape(3, 3)\n",
    "        val =torch.sum(img_subset * model_filter) + cnn_b\n",
    "        sumprod[i, j] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8059, -2.2239],\n",
       "        [-0.9672, -1.4943]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumprod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**perform ReLU operation on top of the output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumprod.clamp_min_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The output of the pooling layer can be calculated like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_layer_output = torch.max(sumprod)\n",
    "pooling_layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pass the output through linear activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4069]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_output_value = pooling_layer_output * lin_w + lin_b\n",
    "intermediate_output_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pass the output through sigmoid operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0321]])\n"
     ]
    }
   ],
   "source": [
    "print(F.sigmoid(intermediate_output_value))  # from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
